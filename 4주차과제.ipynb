{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPh3pUXs5arGclHvMAnwZ7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kt3139/-/blob/master/4%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guj1QWecJJP1",
        "colab_type": "text"
      },
      "source": [
        "4주차 과제\n",
        "\n",
        "1번문제 \n",
        "\n",
        "MCP 뉴런\n",
        ": 워랜 맥컬룩과 월터 피츠는 처음으로 간소화된 뇌의 뉴런 개념\n",
        "\n",
        "\n",
        "퍼셉트론: 자동으로 최적의 가중치를 학습하는 알고리즘\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "역전파: 뉴런의 가중치를 효율적으로 조정하기 위하여, 거꾸로 무엇인가를 전파하는 방식\n",
        "\n",
        "강화학습: 에이전트라는 존재가 환경과 상호작용하며 다양한 시행착오를 겪으며 보상을 최대화하는 방향으로 학습하는 것\n",
        "\n",
        "\n",
        "과적합: 학습 데이터를 과하게 학습하는 것을 말함\n",
        "\n",
        "차원의 저주: 고정된 크기의 훈련 데이터셋 차원이 늘어남에 따라 특성 공간이 점점 희소해 지는 현상\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eFOF8F4K4QI",
        "colab_type": "text"
      },
      "source": [
        "2번 문제\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzR4szNSK5HC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "75388d91-1117-4b2c-81d3-1f0a3c34bc39"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal ([1], 0, 1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x) :\n",
        "  return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid( x * w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000) :\n",
        "  output = sigmoid(x*w)\n",
        "  error = y - output\n",
        "  w = w + x * 0.1 * error\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\",i, \"Error\", error, \"예측 결과:\", output)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error -0.10010598284299604 예측 결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error -0.05178399422833116 예측 결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error -0.034590451977903586 예측 결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error -0.02588962752851373 예측 결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error -0.020658699939863617 예측 결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error -0.017174253993457355 예측 결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error -0.014689506449480992 예측 결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error -0.012829497265431342 예측 결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error -0.011385568271837804 예측 결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error -0.010232493309882492 예측 결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M19MWY84K-Uc",
        "colab_type": "text"
      },
      "source": [
        "3번 문제\n",
        "\n",
        "(1) 학습률이 0.2일 경우 출력층의 노드값\n",
        "2.65\n",
        "\n",
        "\n",
        "(2) 학습률이 0.1과0.2중 기대출력값이 지도데이터\"3\"과 더 가까운 학습률은? 0.2\n"
      ]
    }
  ]
}